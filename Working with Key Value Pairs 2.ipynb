{

 "cells": [

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "#### Aggregations"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 1,

   "metadata": {},

   "outputs": [],

   "source": [

    "pairRDD = sc.parallelize([(1,5),(10,1),(10,12),(1,10),(2,15)])"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "<b>Calculate Per Key average</b>"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},

   "outputs": [],

   "source": [

    "mappedRDD = pairRDD.mapValues(lambda x:(x,1))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 5,

   "metadata": {},

   "outputs": [],

   "source": [

    "intermediateRDD = mappedRDD.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 6,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(10, 6), (2, 15), (1, 7)]"

      ]

     },

     "execution_count": 6,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "intermediateRDD.mapValues(lambda x:x[0]/x[1]).collect()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "#### infamous word count problem"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 11,

   "metadata": {},

   "outputs": [],

   "source": [

    "lines = sc.textFile('file:////home/cloudera/Desktop/pyspark/README.txt')"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 16,

   "metadata": {},

   "outputs": [],

   "source": [

    "wordsRDD = lines.flatMap(lambda x :x.split(\" \")).map(lambda x:(x.lower(),1))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 17,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(u'a', 3),\n",

       " (u'', 2),\n",

       " (u'van', 1),\n",

       " (u'langauege', 1),\n",

       " (u'this', 1),\n",

       " (u'is', 3),\n",

       " (u'sample', 1),\n",

       " (u'python', 2),\n",

       " (u'file', 1),\n",

       " (u'langauge', 1),\n",

       " (u'developed', 1),\n",

       " (u'rosam', 1),\n",

       " (u'functional', 1),\n",

       " (u'by', 1),\n",

       " (u'guido', 1)]"

      ]

     },

     "execution_count": 17,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "countRDD = wordsRDD.reduceByKey(lambda x,y:x+y)\n",

    "countRDD.collect()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "#### This can be implemented much faster by using countByValue()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 20,

   "metadata": {},

   "outputs": [],

   "source": [

    "wordsRDD = lines.flatMap(lambda x :x.split(\" \")).countByValue()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 21,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "defaultdict(int,\n",

       "            {u'': 2,\n",

       "             u'Guido': 1,\n",

       "             u'Python': 2,\n",

       "             u'Rosam': 1,\n",

       "             u'This': 1,\n",

       "             u'Van': 1,\n",

       "             u'a': 3,\n",

       "             u'by': 1,\n",

       "             u'developed': 1,\n",

       "             u'file': 1,\n",

       "             u'functional': 1,\n",

       "             u'is': 3,\n",

       "             u'langauege': 1,\n",

       "             u'langauge': 1,\n",

       "             u'sample': 1})"

      ]

     },

     "execution_count": 21,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "wordsRDD"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "note: countByValue() is an action not a transformation."

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "##### combineByKey()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 22,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(10, (13, 2)), (2, (15, 1)), (1, (15, 2))]"

      ]

     },

     "execution_count": 22,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "pairRDD.mapValues(lambda x:(x,1)).reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1])).collect()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "Per Key average using combineByKey()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 25,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(10, (13, 2)), (2, (15, 1)), (1, (15, 2))]"

      ]

     },

     "execution_count": 25,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "pairRDD.combineByKey(lambda x:(x,1),lambda x,y:(x[0]+y,x[1]+1),lambda x1,x2:(x1[0]+x2[0],x1[1]+x2[1])).collect()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "##### How combineByKey() works"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "Signature :<br>\n",

    "<b>combineByKey(createCombiner(),mergeValue(),mergeCombiner())</b><br>\n",

    "<b><u>createCombiner()</u></b>- If a new key (element) is found in the partition than <b>intial value</b> is created by executing createCombiner() function for that key.Please note this happens evey time a new key is found in new partition rather than in RDD<br>\n",

    "<b><u>mergeValue()</u></b> - If a element found second time then mergevalue() gets executed in which initilt of each partition.al value will the first parameter.<br>\n",

    "<b><u>mergeCombiner()</u></b> - Executed at last to combie the resu"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "#### Find average marks per student"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 1,

   "metadata": {},

   "outputs": [],

   "source": [

    "student_rdd = sc.parallelize([(\"Joseph\", \"Maths\", 83), (\"Joseph\", \"Physics\", 74), (\"Joseph\", \"Chemistry\", 91),\n",

    "                (\"Joseph\", \"Biology\", 82), (\"Jimmy\", \"Maths\", 69), (\"Jimmy\", \"Physics\", 62),\n",

    "                (\"Jimmy\", \"Chemistry\", 97), (\"Jimmy\", \"Biology\", 80), (\"Tina\", \"Maths\", 78),\n",

    "                (\"Tina\", \"Physics\", 73), (\"Tina\", \"Chemistry\", 68), (\"Tina\", \"Biology\", 87),\n",

    "                (\"Thomas\", \"Maths\", 87), (\"Thomas\", \"Physics\", 93), (\"Thomas\", \"Chemistry\", 91),\n",

    "                (\"Thomas\", \"Biology\", 74), (\"Cory\", \"Maths\", 56), (\"Cory\", \"Physics\", 65),\n",

    "                (\"Cory\", \"Chemistry\", 71), (\"Cory\", \"Biology\", 68), (\"Jackeline\", \"Maths\", 86),\n",

    "                (\"Jackeline\", \"Physics\", 62), (\"Jackeline\", \"Chemistry\", 75), (\"Jackeline\", \"Biology\", 83), \n",

    "                (\"Juan\", \"Maths\", 63), (\"Juan\", \"Physics\", 69), (\"Juan\", \"Chemistry\", 64),\n",

    "                (\"Juan\", \"Biology\", 60)], 3)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},

   "outputs": [],

   "source": [

    "mapped_rdd = student_rdd.map(lambda x:(x[0],(x[2],1.0)))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 7,

   "metadata": {},

   "outputs": [],

   "source": [

    "reduced_rdd = mapped_rdd.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 8,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[('Thomas', 86.25),\n",

       " ('Jimmy', 77.0),\n",

       " ('Juan', 64.0),\n",

       " ('Cory', 65.0),\n",

       " ('Jackeline', 76.5),\n",

       " ('Joseph', 82.5),\n",

       " ('Tina', 76.5)]"

      ]

     },

     "execution_count": 8,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "reduced_rdd.mapValues(lambda x:x[0]/x[1]).collect()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "##### Above problem using combineByKey()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 14,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[('Thomas', 86.25),\n",

       " ('Jimmy', 77.0),\n",

       " ('Juan', 64.0),\n",

       " ('Cory', 65.0),\n",

       " ('Jackeline', 76.5),\n",

       " ('Joseph', 82.5),\n",

       " ('Tina', 76.5)]"

      ]

     },

     "execution_count": 14,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd.map(lambda x:(x[0],(x[2])))\\\n",

    "        .combineByKey(lambda x:(x,1),\\\n",

    "                      lambda x,y:(x[0]+y,x[1]+1.0),\\\n",

    "                      lambda x,y:(x[0]+y[0],x[1]+y[1])\\\n",

    "                     )\\\n",

    "        .mapValues(lambda x:x[0]/x[1])\\\n",

    "        .collect()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},

   "outputs": [],

   "source": [

    "#find the sum of marks per student"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 14,

   "metadata": {},

   "outputs": [],

   "source": [

    "student_rdd_mapped = student_rdd.map(lambda x :(x[0],(x[2],1)))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 15,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[('Tina', (87, 1)),\n",

       " ('Tina', (78, 1)),\n",

       " ('Tina', (73, 1)),\n",

       " ('Tina', (68, 1)),\n",

       " ('Thomas', (93, 1))]"

      ]

     },

     "execution_count": 15,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd_mapped.top(5)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 16,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[('Thomas', (345, 4)),\n",

       " ('Jimmy', (308, 4)),\n",

       " ('Juan', (256, 4)),\n",

       " ('Cory', (260, 4)),\n",

       " ('Jackeline', (306, 4)),\n",

       " ('Joseph', (330, 4)),\n",

       " ('Tina', (306, 4))]"

      ]

     },

     "execution_count": 16,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd_mapped.reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1])).collect()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "Note: While using reduceByKey() please note that type of lambda function output and the type of the value of the RDD should be the same."

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "##### Tuning the level of Parallelism"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 1,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "PythonRDD[10] at RDD at PythonRDD.scala:43"

      ]

     },

     "execution_count": 1,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "data = [(\"a\",1),(\"b\",2),(\"a\",12)]\n",

    "sc.parallelize(data).reduceByKey(lambda x,y:x+y) #default parallelism\n",

    "sc.parallelize(data).reduceByKey(lambda x,y:x+y,10)#custom parallelism"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    " <b>repartition() and coalesce()</b>"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 19,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "MapPartitionsRDD[54] at repartition at NativeMethodAccessorImpl.java:-2"

      ]

     },

     "execution_count": 19,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "#repartition()\n",

    "#shuffles the data across the nodes to create new set of partition\n",

    "student_rdd.repartition(2)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 20,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "3"

      ]

     },

     "execution_count": 20,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd.getNumPartitions()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 22,

   "metadata": {},

   "outputs": [],

   "source": [

    "student_rdd = student_rdd.repartition(2)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 23,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "2"

      ]

     },

     "execution_count": 23,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd.getNumPartitions()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "<b>Note</b>: repartition() is really expensive since  it involves shuffling of the data ."

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "coalesce() avoids shuffling of the data only  if number of partitions is decreased.<br>\n",

    "To use it we have to check the correct partition size."

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 24,

   "metadata": {},

   "outputs": [],

   "source": [

    "student_rdd = student_rdd.coalesce(1)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 25,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "1"

      ]

     },

     "execution_count": 25,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd.getNumPartitions()"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "#### Grouping Data"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 5,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[('Thomas', <pyspark.resultiterable.ResultIterable at 0x7fb0a449b4d0>),\n",

       " ('Jimmy', <pyspark.resultiterable.ResultIterable at 0x7fb0a449bad0>),\n",

       " ('Juan', <pyspark.resultiterable.ResultIterable at 0x7fb0a449b6d0>),\n",

       " ('Cory', <pyspark.resultiterable.ResultIterable at 0x7fb0a449b650>),\n",

       " ('Jackeline', <pyspark.resultiterable.ResultIterable at 0x7fb0a449b890>),\n",

       " ('Joseph', <pyspark.resultiterable.ResultIterable at 0x7fb0a449b5d0>),\n",

       " ('Tina', <pyspark.resultiterable.ResultIterable at 0x7fb0a449b490>)]"

      ]

     },

     "execution_count": 5,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "student_rdd.groupBy(lambda x:x[0]).collect()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 6,

   "metadata": {},

   "outputs": [],

   "source": [

    "sampleRDD = sc.parallelize([('pp','India',10),\n",

    "                           ('aa','Israel',25),('pp','India'),('pp','India',100),('aa','Israel',14),\n",

    "                           ('ss','Switerzealand',11)])"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 10,

   "metadata": {},

   "outputs": [

    {

     "ename": "SyntaxError",

     "evalue": "unexpected EOF while parsing (<ipython-input-10-7833bd6fa1d9>, line 1)",

     "output_type": "error",

     "traceback": [

      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-7833bd6fa1d9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sampleRDD.groupBy(lambda x:(x[0]).collect()\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"

     ]

    }

   ],

   "source": []

  },

  {

   "cell_type": "code",

   "execution_count": 11,

   "metadata": {},

   "outputs": [],

   "source": [

    "tempRDD = sc.parallelize([(3922774869,10,1),\n",

    "(3922774869,11,1),\n",

    "(3922774869,12,2),\n",

    "(3922774869,13,2),\n",

    "(1779744180,10,1),\n",

    "(1779744180,11,1),\n",

    "(3922774869,14,3),\n",

    "(3922774869,15,2),\n",

    "(1779744180,16,1),\n",

    "(3922774869,12,1),\n",

    "(3922774869,13,1),\n",

    "(1779744180,14,1),\n",

    "(1779744180,15,1),\n",

    "(1779744180,16,1),\n",

    "(3922774869,14,2),\n",

    "(3922774869,15,1),\n",

    "(1779744180,16,1),\n",

    "(1779744180,17,1),\n",

    "(3922774869,16,4)\n",

    "          ])"

   ]

  },

  {

   "cell_type": "markdown",

   "metadata": {},

   "source": [

    "Output expectation : (1779744180, (10,1), (11,1), (12,2), (13,2) ...)\n",

    "(3922774869, (10,1), (11,1), (12,3), (13,4) ...)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 29,

   "metadata": {},

   "outputs": [],

   "source": [

    "k = tempRDD.map(lambda x :(x[0],x[1:]))"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 30,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(3922774869, (10, 1)),\n",

       " (3922774869, (11, 1)),\n",

       " (3922774869, (12, 2)),\n",

       " (3922774869, (13, 2)),\n",

       " (1779744180, (10, 1)),\n",

       " (1779744180, (11, 1)),\n",

       " (3922774869, (14, 3)),\n",

       " (3922774869, (15, 2)),\n",

       " (1779744180, (16, 1)),\n",

       " (3922774869, (12, 1)),\n",

       " (3922774869, (13, 1)),\n",

       " (1779744180, (14, 1)),\n",

       " (1779744180, (15, 1)),\n",

       " (1779744180, (16, 1)),\n",

       " (3922774869, (14, 2)),\n",

       " (3922774869, (15, 1)),\n",

       " (1779744180, (16, 1)),\n",

       " (1779744180, (17, 1)),\n",

       " (3922774869, (16, 4))]"

      ]

     },

     "execution_count": 30,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "k.collect()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 39,

   "metadata": {},

   "outputs": [],

   "source": [

    "def h(x,y):\n",

    "    x.append(y)\n",

    "    return x"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 40,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(1779744180,\n",

       "  [(10, 1), (11, 1), (16, 1), [(14, 1), (15, 1), (16, 1), (16, 1), (17, 1)]]),\n",

       " (3922774869,\n",

       "  [(10, 1),\n",

       "   (11, 1),\n",

       "   (12, 2),\n",

       "   (13, 2),\n",

       "   (14, 3),\n",

       "   (15, 2),\n",

       "   [(12, 1), (13, 1), (14, 2), (15, 1), (16, 4)]])]"

      ]

     },

     "execution_count": 40,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "k.aggregateByKey([],h,h).collect()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": []

  },

  {

   "cell_type": "code",

   "execution_count": 31,

   "metadata": {},

   "outputs": [

    {

     "data": {

      "text/plain": [

       "[(1779744180, (10, 1, 11, 1, 16, 1, 14, 1, 15, 1, 16, 1, 16, 1, 17, 1)),\n",

       " (3922774869,\n",

       "  (10,\n",

       "   1,\n",

       "   11,\n",

       "   1,\n",

       "   12,\n",

       "   2,\n",

       "   13,\n",

       "   2,\n",

       "   14,\n",

       "   3,\n",

       "   15,\n",

       "   2,\n",

       "   12,\n",

       "   1,\n",

       "   13,\n",

       "   1,\n",

       "   14,\n",

       "   2,\n",

       "   15,\n",

       "   1,\n",

       "   16,\n",

       "   4))]"

      ]

     },

     "execution_count": 31,

     "metadata": {},

     "output_type": "execute_result"

    }

   ],

   "source": [

    "k.reduceByKey(lambda x,y :x+y).collect()"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "metadata": {},

   "outputs": [],

   "source": []

  }

 ],

 "metadata": {

  "kernelspec": {

   "display_name": "Python 2",

   "language": "python",

   "name": "python2"

  },

  "language_info": {

   "codemirror_mode": {

    "name": "ipython",

    "version": 2

   },

   "file_extension": ".py",

   "mimetype": "text/x-python",

   "name": "python",

   "nbconvert_exporter": "python",

   "pygments_lexer": "ipython2",

   "version": "2.7.17"

  }

 },

 "nbformat": 4,

 "nbformat_minor": 2

}